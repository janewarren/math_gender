{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51767969",
   "metadata": {},
   "source": [
    "# clean_results\n",
    "\n",
    "load all raw converted TSV files, fix known extraction/ground-truth bugs, and save a single clean parquet for analysis.\n",
    "\n",
    "**bugs fixed here:**\n",
    "1. **timezone ground truth** — `preprocessing.py` used `int()` instead of `round()` when formatting minutes, making most timezone correct answers off by 1 minute. we recompute them from the raw inputs.\n",
    "2. **timezone math_only model_answer** — the math_only prompt is pure arithmetic (`(1+3.0)%24`), so models respond with a decimal number instead of a time string. `extract_time_string` returns None. we interpret those numbers as 24-hour decimal time.\n",
    "3. **bra_size model_answer** — `extract_clothing_size` regex can't handle double-letter cup sizes (`32AA`) or single-digit Italian band sizes (`1A`). we expand the regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4adf5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41f842",
   "metadata": {},
   "source": [
    "## 1. load all raw results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d41593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 2,748,418 rows from 279 files\n",
      "columns: ['domain', 'distractor', 'prompt', 'number', 'answer', 'difficulty', 'raw_response', 'model_answer', 'loss', 'reasoning_tokens', 'call_seconds', 'model', 'condition']\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path('full_results')\n",
    "\n",
    "CONDITIONS = {\n",
    "    'regular':   'results',\n",
    "    'no_guide':  'results_no_guide',\n",
    "    'math_only': 'results_math_only',\n",
    "}\n",
    "SUBDIR_TO_CONDITION = {v: k for k, v in CONDITIONS.items()}\n",
    "\n",
    "NON_REASONING = ['gpt-4o', 'qwen-coder', 'llama-4']\n",
    "REASONING = ['gpt-5.2', 'deepseek-v3.1', 'qwen3-235b-thinking', 'qwen3-next-thinking']\n",
    "\n",
    "def parse_model(f):\n",
    "    return f.parts[2]\n",
    "\n",
    "def parse_cond(f):\n",
    "    return SUBDIR_TO_CONDITION.get(f.parts[1], f.parts[1])\n",
    "\n",
    "def parse_domain(f):\n",
    "    return (f.parts[3]\n",
    "            .replace('_converted', '')\n",
    "            .replace('_math_only', '')\n",
    "            .replace('_no_guide', '')\n",
    "            .replace('.tsv', ''))\n",
    "\n",
    "# load every TSV and tag with model/condition/domain\n",
    "files = sorted(BASE_DIR.glob('*/*/*_converted.tsv'))\n",
    "frames = []\n",
    "for f in files:\n",
    "    try:\n",
    "        df = pd.read_csv(f, sep='\\t')\n",
    "        df = df.assign(model=parse_model(f), condition=parse_cond(f), domain=parse_domain(f))\n",
    "        frames.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Could not read {f}: {e}\")\n",
    "\n",
    "df_all = pd.concat(frames, ignore_index=True)\n",
    "print(f\"loaded {len(df_all):,} rows from {len(files)} files\")\n",
    "print(f\"columns: {df_all.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b239904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered 652,650 invalid rows → 2,095,768 remaining\n",
      "NaN model_answer before fixes: 382 (0.02%)\n"
     ]
    }
   ],
   "source": [
    "# filter out invalid responses\n",
    "_before = len(df_all)\n",
    "df_all = df_all[\n",
    "    df_all['raw_response'].notna()\n",
    "    & ~df_all['raw_response'].isin(['null', 'nan'])\n",
    "    & ~df_all['raw_response'].astype(str).str.startswith('ERROR:')\n",
    "    & ~df_all['raw_response'].astype(str).str.contains('model_not_available', na=False)\n",
    "]\n",
    "print(f\"filtered {_before - len(df_all):,} invalid rows → {len(df_all):,} remaining\")\n",
    "\n",
    "# add helper columns\n",
    "df_all['is_reasoning'] = df_all['model'].isin(REASONING)\n",
    "\n",
    "# snapshot of NaN model_answer before any fixes\n",
    "_nan_before = df_all['model_answer'].isna().sum()\n",
    "print(f\"NaN model_answer before fixes: {_nan_before:,} ({_nan_before/len(df_all)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d055f563",
   "metadata": {},
   "source": [
    "## 2. fix timezone ground truth (all conditions)\n",
    "\n",
    "the `format_time_string` function in `preprocessing.py` used `int((hours % 1) * 60)` which truncates instead of rounding, making most generated correct answers off by 1 minute. recompute from raw inputs using `round()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d307736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timezone rows: 10,800\n",
      "Ground truth answers changed: 0 (0.0%)\n",
      "Empty DataFrame\n",
      "Columns: [input, old_answer, new_answer]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# ── time parsing / formatting helpers ────────────────────────────\n",
    "\n",
    "def parse_time(s):\n",
    "    \"\"\"Parse '7:13PM' or '1AM' → hours as float (24h).\"\"\"\n",
    "    s = s.strip().upper()\n",
    "    m = re.match(r'(\\d{1,2}):(\\d{2})\\s*(AM|PM)', s)\n",
    "    if m:\n",
    "        h, mi, p = int(m.group(1)), int(m.group(2)), m.group(3)\n",
    "        if p == 'PM' and h != 12: h += 12\n",
    "        elif p == 'AM' and h == 12: h = 0\n",
    "        return h + mi / 60.0\n",
    "    m = re.match(r'(\\d{1,2})\\s*(AM|PM)', s)\n",
    "    if m:\n",
    "        h, p = int(m.group(1)), m.group(2)\n",
    "        if p == 'PM' and h != 12: h += 12\n",
    "        elif p == 'AM' and h == 12: h = 0\n",
    "        return float(h)\n",
    "    return None\n",
    "\n",
    "def format_time(hours):\n",
    "    \"\"\"24h decimal hours → '7:13PM'. uses round() to avoid truncation.\"\"\"\n",
    "    hours = hours % 24\n",
    "    total_min = round(hours * 60)\n",
    "    h = (total_min // 60) % 24\n",
    "    m = total_min % 60\n",
    "    if m == 0:\n",
    "        if h == 0:     return \"12AM\"\n",
    "        elif h < 12:   return f\"{h}AM\"\n",
    "        elif h == 12:  return \"12PM\"\n",
    "        else:          return f\"{h-12}PM\"\n",
    "    else:\n",
    "        if h == 0:     return f\"12:{m:02d}AM\"\n",
    "        elif h < 12:   return f\"{h}:{m:02d}AM\"\n",
    "        elif h == 12:  return f\"12:{m:02d}PM\"\n",
    "        else:          return f\"{h-12}:{m:02d}PM\"\n",
    "\n",
    "# ── load timezone config ─────────────────────────────────────────\n",
    "\n",
    "with open('conversions/timezone.json') as f:\n",
    "    tz_config = json.load(f)\n",
    "tz_offsets = tz_config['timezone_offsets']\n",
    "city_to_tz = tz_config['city_to_timezone']\n",
    "\n",
    "def convert_tz(time_str, from_city, to_city):\n",
    "    \"\"\"Recompute correct timezone answer from raw inputs.\"\"\"\n",
    "    hours = parse_time(time_str)\n",
    "    if hours is None:\n",
    "        return None\n",
    "    from_off = tz_offsets.get(city_to_tz.get(from_city, from_city), 0)\n",
    "    to_off   = tz_offsets.get(city_to_tz.get(to_city,   to_city),   0)\n",
    "    return format_time((hours - from_off + to_off) % 24)\n",
    "\n",
    "# ── recompute correct answers for all timezone rows ──────────────\n",
    "\n",
    "tz_mask = df_all['domain'] == 'timezone'\n",
    "old_answers = df_all.loc[tz_mask, 'answer'].copy()\n",
    "prompts     = df_all.loc[tz_mask, 'prompt'].astype(str)\n",
    "input_times = df_all.loc[tz_mask, 'number'].astype(str)\n",
    "\n",
    "# prompt format: \"Convert {time} in {from_city} time to {to_city} time...\"\n",
    "parsed = prompts.str.extract(r'Convert .+? in (.+?) time to (.+?) time')\n",
    "\n",
    "new_answers = [\n",
    "    convert_tz(t, fc, tc) if pd.notna(fc) else old\n",
    "    for t, fc, tc, old in zip(input_times, parsed[0], parsed[1], old_answers)\n",
    "]\n",
    "df_all.loc[tz_mask, 'answer'] = new_answers\n",
    "\n",
    "changed = (old_answers.values != np.array(new_answers))\n",
    "print(f\"Timezone rows: {tz_mask.sum():,}\")\n",
    "print(f\"Ground truth answers changed: {changed.sum():,} ({changed.mean()*100:.1f}%)\")\n",
    "\n",
    "# show a few examples\n",
    "idx = old_answers.index[changed][:5]\n",
    "print(pd.DataFrame({\n",
    "    'input': input_times.loc[idx].values,\n",
    "    'old_answer': old_answers.loc[idx].values,\n",
    "    'new_answer': [new_answers[list(old_answers.index).index(i)] for i in idx],\n",
    "}).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7763a4",
   "metadata": {},
   "source": [
    "## 3. fix timezone math_only model_answer extraction\n",
    "\n",
    "the math_only prompt is pure arithmetic (`(1+3.0)%24`) so models reply with decimal hours. `extract_time_string` needs AM/PM and returns None. re-extract by interpreting the numeric response as 24h decimal time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac87eabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math-only timezone rows: 3,600\n",
      "  model_answer was NaN: 0\n",
      "  model_answer now NaN: 0\n",
      "  recovered:            0\n",
      "\n",
      "Recovered examples:\n",
      "Empty DataFrame\n",
      "Columns: [answer, model_answer, model]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def extract_tz_answer(raw_response, is_reasoning):\n",
    "    \"\"\"Extract a timezone answer from a raw response.\n",
    "    \n",
    "    Priority:\n",
    "    1. If response has a proper time string (H:MMAM/PM or HAM/PM), use it.\n",
    "    2. Otherwise extract a number (from <answer> tags if reasoning model,\n",
    "       else from the raw text) and interpret as 24h decimal time.\n",
    "    \"\"\"\n",
    "    resp = str(raw_response)\n",
    "\n",
    "    # for reasoning models, prefer <answer> tag content\n",
    "    source = resp\n",
    "    if is_reasoning:\n",
    "        tags = re.findall(r'<answer>\\s*(.*?)\\s*</answer>', resp, re.DOTALL)\n",
    "        if tags:\n",
    "            source = tags[-1].strip()\n",
    "\n",
    "    # try proper time string first\n",
    "    m = re.search(r'(\\d{1,2}):(\\d{2})\\s*(AM|PM)', source, re.IGNORECASE)\n",
    "    if m and 1 <= int(m.group(1)) <= 12 and 0 <= int(m.group(2)) <= 59:\n",
    "        return f\"{int(m.group(1))}:{int(m.group(2)):02d}{m.group(3).upper()}\"\n",
    "    m = re.search(r'(\\d{1,2})\\s*(AM|PM)', source, re.IGNORECASE)\n",
    "    if m and 1 <= int(m.group(1)) <= 12:\n",
    "        return f\"{int(m.group(1))}{m.group(2).upper()}\"\n",
    "\n",
    "    # fall back: extract a number and interpret as decimal hours\n",
    "    num_match = re.search(r'-?\\d+\\.?\\d*', source)\n",
    "    if num_match:\n",
    "        try:\n",
    "            hours = float(num_match.group(0)) % 24\n",
    "            return format_time(hours)\n",
    "        except (ValueError, OverflowError):\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "# apply to math_only timezone rows\n",
    "math_tz = (df_all['domain'] == 'timezone') & (df_all['condition'] == 'math_only')\n",
    "old_ma = df_all.loc[math_tz, 'model_answer'].copy()\n",
    "\n",
    "df_all.loc[math_tz, 'model_answer'] = [\n",
    "    extract_tz_answer(resp, is_r)\n",
    "    for resp, is_r in zip(df_all.loc[math_tz, 'raw_response'],\n",
    "                          df_all.loc[math_tz, 'is_reasoning'])\n",
    "]\n",
    "\n",
    "was_nan = old_ma.isna()\n",
    "now_nan = df_all.loc[math_tz, 'model_answer'].isna()\n",
    "recovered = was_nan & ~now_nan\n",
    "print(f\"Math-only timezone rows: {math_tz.sum():,}\")\n",
    "print(f\"  model_answer was NaN: {was_nan.sum():,}\")\n",
    "print(f\"  model_answer now NaN: {now_nan.sum():,}\")\n",
    "print(f\"  recovered:            {recovered.sum():,}\")\n",
    "\n",
    "# examples\n",
    "sample = df_all.loc[old_ma.index[recovered][:6], ['answer', 'model_answer', 'model']]\n",
    "print(\"\\nRecovered examples:\")\n",
    "print(sample.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e6883b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb44d048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      32AA →     32AA  ✓\n",
      "      34AA →     34AA  ✓\n",
      "        1A →       1A  ✓\n",
      "        1B →       1B  ✓\n",
      "       32B →      32B  ✓\n",
      "       70A →      70A  ✓\n",
      "       85C →      85C  ✓\n",
      "        XL →       XL  ✓\n",
      "      42.5 →     42.5  ✓\n",
      "\n",
      "Bra-size rows: 1,568\n",
      "  model_answer was NaN: 5\n",
      "  model_answer now NaN: 5\n",
      "  recovered:            0\n"
     ]
    }
   ],
   "source": [
    "def extract_clothing_size_fixed(answer):\n",
    "    \"\"\"Extract a clothing size, handling AA cups and single-digit Italian bands.\"\"\"\n",
    "    if not answer or pd.isna(answer):\n",
    "        return None\n",
    "    answer = str(answer).strip()\n",
    "\n",
    "    # bra size: number + one or more cup letters (32AA, 70A, 1B, 100D)\n",
    "    m = re.search(r'\\b(\\d{1,3})([A-Za-z]{1,3})\\b', answer)\n",
    "    if m:\n",
    "        return f\"{m.group(1)}{m.group(2).upper()}\"\n",
    "\n",
    "    # alpha sizes (XS, S, M, L, etc.)\n",
    "    m = re.search(r'\\b(XS|S|M|L|XL|XXL|XXXL)\\b', answer, re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).upper()\n",
    "\n",
    "    # numeric sizes (shoe sizes, pants)\n",
    "    m = re.search(r'\\b(\\d{1,3}\\.?\\d*)\\b', answer)\n",
    "    if m:\n",
    "        try:\n",
    "            num = float(m.group(1))\n",
    "            return str(int(num)) if num == int(num) else f\"{num:.1f}\".rstrip('0').rstrip('.')\n",
    "        except ValueError:\n",
    "            return m.group(1)\n",
    "    return None\n",
    "\n",
    "# quick sanity check\n",
    "_tests = {'32AA': '32AA', '34AA': '34AA', '1A': '1A', '1B': '1B',\n",
    "          '32B': '32B', '70A': '70A', '85C': '85C', 'XL': 'XL', '42.5': '42.5'}\n",
    "for inp, expected in _tests.items():\n",
    "    got = extract_clothing_size_fixed(inp)\n",
    "    status = '✓' if got == expected else f'✗ (got {got})'\n",
    "    print(f\"  {inp:>8s} → {got:>8s}  {status}\")\n",
    "\n",
    "# apply to ALL bra_size rows (re-extract model_answer)\n",
    "bra_mask = df_all['domain'].str.contains('bra_size')\n",
    "old_bra_ma = df_all.loc[bra_mask, 'model_answer'].copy()\n",
    "\n",
    "def re_extract_bra(row):\n",
    "    resp = str(row['raw_response'])\n",
    "    # reasoning: try <answer> tags first\n",
    "    source = resp\n",
    "    if row['is_reasoning']:\n",
    "        tags = re.findall(r'<answer>\\s*(.*?)\\s*</answer>', resp, re.DOTALL)\n",
    "        if tags:\n",
    "            source = tags[-1].strip()\n",
    "    return extract_clothing_size_fixed(source)\n",
    "\n",
    "df_all.loc[bra_mask, 'model_answer'] = df_all.loc[bra_mask].apply(re_extract_bra, axis=1)\n",
    "\n",
    "was_nan = old_bra_ma.isna()\n",
    "now_nan = df_all.loc[bra_mask, 'model_answer'].isna()\n",
    "recovered = was_nan & ~now_nan\n",
    "print(f\"\\nBra-size rows: {bra_mask.sum():,}\")\n",
    "print(f\"  model_answer was NaN: {was_nan.sum():,}\")\n",
    "print(f\"  model_answer now NaN: {now_nan.sum():,}\")\n",
    "print(f\"  recovered:            {recovered.sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e62696",
   "metadata": {},
   "source": [
    "## 5. recompute loss for all fixed rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08985813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomputing timezone loss (all conditions)...\n",
      "  timezone accuracy before: 7,366 / 10,800 (68.2%)\n",
      "  timezone accuracy after:  7,366 / 10,800 (68.2%)\n",
      "\n",
      "Recomputing bra-size loss...\n",
      "  bra-size accuracy before: 1,003 / 1,568 (64.0%)\n",
      "  bra-size accuracy after:  1,003 / 1,568 (64.0%)\n"
     ]
    }
   ],
   "source": [
    "# ── loss functions (mirroring extractors.py) ─────────────────────\n",
    "\n",
    "def tz_loss(model_ans, correct_ans, tolerance_minutes=1.0):\n",
    "    \"\"\"Minutes difference, 0.0 if within tolerance.\"\"\"\n",
    "    try:\n",
    "        m_hrs = parse_time(str(model_ans))\n",
    "        c_hrs = parse_time(str(correct_ans))\n",
    "        if m_hrs is None or c_hrs is None:\n",
    "            return None\n",
    "        diff = abs((m_hrs - c_hrs) * 60)\n",
    "        if diff > 720:\n",
    "            diff = 1440 - diff\n",
    "        return 0.0 if diff <= tolerance_minutes + 1e-9 else round(diff, 4)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def clothing_loss(model_ans, correct_ans):\n",
    "    \"\"\"Binary: 0.0 if match, 1.0 if not.\"\"\"\n",
    "    if model_ans is None or pd.isna(model_ans):\n",
    "        return None\n",
    "    try:\n",
    "        return 0.0 if abs(float(str(model_ans).strip()) - float(str(correct_ans).strip())) < 0.001 else 1.0\n",
    "    except (ValueError, TypeError):\n",
    "        return 0.0 if str(model_ans).strip().upper() == str(correct_ans).strip().upper() else 1.0\n",
    "\n",
    "# ── recompute timezone loss (all conditions — ground truth changed) ──\n",
    "\n",
    "print(\"Recomputing timezone loss (all conditions)...\")\n",
    "new_tz_losses = [\n",
    "    tz_loss(ma, ca)\n",
    "    for ma, ca in zip(df_all.loc[tz_mask, 'model_answer'], df_all.loc[tz_mask, 'answer'])\n",
    "]\n",
    "old_tz_correct = (pd.to_numeric(df_all.loc[tz_mask, 'loss'], errors='coerce') == 0).sum()\n",
    "df_all.loc[tz_mask, 'loss'] = new_tz_losses\n",
    "new_tz_correct = sum(1 for l in new_tz_losses if l == 0.0)\n",
    "print(f\"  timezone accuracy before: {old_tz_correct:,} / {tz_mask.sum():,} ({old_tz_correct/tz_mask.sum()*100:.1f}%)\")\n",
    "print(f\"  timezone accuracy after:  {new_tz_correct:,} / {tz_mask.sum():,} ({new_tz_correct/tz_mask.sum()*100:.1f}%)\")\n",
    "\n",
    "# ── recompute bra_size loss ──────────────────────────────────────\n",
    "\n",
    "print(\"\\nRecomputing bra-size loss...\")\n",
    "new_bra_losses = [\n",
    "    clothing_loss(ma, ca)\n",
    "    for ma, ca in zip(df_all.loc[bra_mask, 'model_answer'], df_all.loc[bra_mask, 'answer'])\n",
    "]\n",
    "old_bra_correct = (pd.to_numeric(df_all.loc[bra_mask, 'loss'], errors='coerce') == 0).sum()\n",
    "df_all.loc[bra_mask, 'loss'] = new_bra_losses\n",
    "new_bra_correct = sum(1 for l in new_bra_losses if l == 0.0)\n",
    "print(f\"  bra-size accuracy before: {old_bra_correct:,} / {bra_mask.sum():,} ({old_bra_correct/bra_mask.sum()*100:.1f}%)\")\n",
    "print(f\"  bra-size accuracy after:  {new_bra_correct:,} / {bra_mask.sum():,} ({new_bra_correct/bra_mask.sum()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e287827",
   "metadata": {},
   "source": [
    "## 6. summary & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef24aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN model_answer: 382 → 382  (recovered 0)\n",
      "Remaining NaN breakdown:\n",
      "  clothing_sizes_women_bra_size                :     5\n",
      "  cooking                                      :    19\n",
      "  currency                                     :    23\n",
      "  density                                      :    13\n",
      "  energy                                       :   121\n",
      "  moles_to_particles                           :    25\n",
      "  timezone                                     :    16\n",
      "  volume                                       :   160\n",
      "\n",
      "Total clean rows: 2,095,768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: ['deepseek-v3.1', 'gpt-4o', 'gpt-5.2', 'llama-4', 'qwen-coder', 'qwen3-235b-thinking', 'qwen3-next-thinking']\n",
      "Conditions: ['math_only', 'no_guide', 'regular']\n",
      "Domains: ['bits_bytes', 'clothing_sizes_men_pant_size', 'clothing_sizes_men_shoe_size', 'clothing_sizes_women_bra_size', 'clothing_sizes_women_pant_size', 'clothing_sizes_women_shoe_size', 'cooking', 'currency', 'density', 'energy', 'moles_to_particles', 'speed', 'temperature', 'timezone', 'volume']\n"
     ]
    }
   ],
   "source": [
    "# final NaN check\n",
    "nan_after = df_all['model_answer'].isna().sum()\n",
    "print(f\"NaN model_answer: {_nan_before:,} → {nan_after:,}  (recovered {_nan_before - nan_after:,})\")\n",
    "print(f\"Remaining NaN breakdown:\")\n",
    "nan_rows = df_all[df_all['model_answer'].isna()]\n",
    "for domain in sorted(nan_rows['domain'].unique()):\n",
    "    n = (nan_rows['domain'] == domain).sum()\n",
    "    print(f\"  {domain:45s}: {n:>5d}\")\n",
    "\n",
    "print(f\"\\nTotal clean rows: {len(df_all):,}\")\n",
    "print(f\"Models: {sorted(df_all['model'].unique())}\")\n",
    "print(f\"Conditions: {sorted(df_all['condition'].unique())}\")\n",
    "print(f\"Domains: {sorted(df_all['domain'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e65eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "full_results/results_no_guide/deepseek-v3.1/timezone_no_guide_converted.tsv  (16 rows changed out of 600)\n",
      "loss_old loss_new\n",
      "     nan     None\n",
      "     nan     None\n",
      "     nan     None\n",
      "     nan     None\n",
      "     nan     None\n",
      "  ... and 11 more\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "full_results/results_no_guide/llama-4/clothing_sizes_women_bra_size_no_guide_converted.tsv  (5 rows changed out of 112)\n",
      "model_answer_old model_answer_new loss_old loss_new\n",
      "             nan             None      nan     None\n",
      "             nan             None      nan     None\n",
      "             nan             None      nan     None\n",
      "             nan             None      nan     None\n",
      "             nan             None      nan     None\n",
      "\n",
      "════════════════════════════════════════════════════════════\n",
      "TOTAL: 2 files with changes, 21 rows affected\n",
      "       277 files unchanged\n"
     ]
    }
   ],
   "source": [
    "# ── DRY RUN: preview what would change in each TSV ──────────────\n",
    "# Strategy: load original file, identify its valid rows (same filter as cell 4),\n",
    "# patch only the answer/model_answer/loss columns from df_all, then compare.\n",
    "# This preserves ALL rows (including errors/nulls) — we only touch valid ones.\n",
    "\n",
    "TAG_COLS = ['model', 'condition', 'domain', 'is_reasoning']\n",
    "FIX_COLS = ['answer', 'model_answer', 'loss']\n",
    "\n",
    "tsv_files = sorted(BASE_DIR.glob('*/*/*_converted.tsv'))\n",
    "total_changed_rows = 0\n",
    "files_with_changes = 0\n",
    "\n",
    "def _valid_mask(df):\n",
    "    \"\"\"Same filter as cell 4.\"\"\"\n",
    "    return (\n",
    "        df['raw_response'].notna()\n",
    "        & ~df['raw_response'].isin(['null', 'nan'])\n",
    "        & ~df['raw_response'].astype(str).str.startswith('ERROR:')\n",
    "        & ~df['raw_response'].astype(str).str.contains('model_not_available', na=False)\n",
    "    )\n",
    "\n",
    "for f in tsv_files:\n",
    "    cond = parse_cond(f)\n",
    "    model = parse_model(f)\n",
    "    domain = parse_domain(f)\n",
    "    mem_mask = (\n",
    "        (df_all['model'] == model)\n",
    "        & (df_all['condition'] == cond)\n",
    "        & (df_all['domain'] == domain)\n",
    "    )\n",
    "    if mem_mask.sum() == 0:\n",
    "        continue\n",
    "\n",
    "    orig = pd.read_csv(f, sep='\\t')\n",
    "    valid = _valid_mask(orig)\n",
    "\n",
    "    # the K-th valid row in orig corresponds to the K-th row in df_all[mem_mask]\n",
    "    fixed_vals = df_all.loc[mem_mask, FIX_COLS].reset_index(drop=True)\n",
    "    assert valid.sum() == len(fixed_vals), (\n",
    "        f\"{f}: {valid.sum()} valid rows on disk vs {len(fixed_vals)} in df_all\"\n",
    "    )\n",
    "\n",
    "    # build patched copy — only update valid rows\n",
    "    patched = orig.copy()\n",
    "    valid_idx = orig.index[valid]\n",
    "    for col in FIX_COLS:\n",
    "        patched.loc[valid_idx, col] = fixed_vals[col].values\n",
    "\n",
    "    # compare original vs patched (all rows, same length)\n",
    "    old_cmp = orig[FIX_COLS].astype(str).fillna('')\n",
    "    new_cmp = patched[FIX_COLS].astype(str).fillna('')\n",
    "    row_changed = (old_cmp != new_cmp).any(axis=1)\n",
    "    n_changed = row_changed.sum()\n",
    "\n",
    "    if n_changed > 0:\n",
    "        total_changed_rows += n_changed\n",
    "        files_with_changes += 1\n",
    "        print(f\"\\n{'─'*60}\")\n",
    "        print(f\"{f}  ({n_changed} rows changed out of {len(orig)})\")\n",
    "        idx = row_changed[row_changed].index[:5]\n",
    "        diff_rows = []\n",
    "        for i in idx:\n",
    "            row = {}\n",
    "            for col in FIX_COLS:\n",
    "                o, n_ = old_cmp.at[i, col], new_cmp.at[i, col]\n",
    "                if o != n_:\n",
    "                    row[f'{col}_old'] = o\n",
    "                    row[f'{col}_new'] = n_\n",
    "            diff_rows.append(row)\n",
    "        print(pd.DataFrame(diff_rows).to_string(index=False))\n",
    "        if n_changed > 5:\n",
    "            print(f\"  ... and {n_changed - 5} more\")\n",
    "\n",
    "print(f\"\\n{'═'*60}\")\n",
    "print(f\"TOTAL: {files_with_changes} files with changes, {total_changed_rows:,} rows affected\")\n",
    "print(f\"       {len(tsv_files) - files_with_changes} files unchanged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a9324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ all 279 TSV files already backed up in full_results_backup/\n"
     ]
    }
   ],
   "source": [
    "# ── backup existing TSVs before overwriting ──────────────────────\n",
    "import shutil\n",
    "\n",
    "BACKUP_DIR = Path('full_results_backup')\n",
    "tsv_files = sorted(BASE_DIR.glob('*/*/*_converted.tsv'))\n",
    "\n",
    "backed_up = 0\n",
    "for f in tsv_files:\n",
    "    dest = BACKUP_DIR / f.relative_to(BASE_DIR)\n",
    "    if dest.exists():\n",
    "        continue  # already backed up — don't overwrite original backup\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(f, dest)\n",
    "    backed_up += 1\n",
    "\n",
    "if backed_up:\n",
    "    print(f\"✓ backed up {backed_up} new TSV files to {BACKUP_DIR}/\")\n",
    "else:\n",
    "    print(f\"✓ all {len(tsv_files)} TSV files already backed up in {BACKUP_DIR}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06ffc350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ updated 257 TSV files in-place (all rows preserved)\n",
      "✓ saved 2,748,418 rows to full_results/clean_results.tsv (includes error/refusal rows)\n",
      "  file size: 1323.6 MB\n"
     ]
    }
   ],
   "source": [
    "# ── write back to each TSV in-place ──────────────────────────────\n",
    "# Load each original file, patch only the answer/model_answer/loss\n",
    "# columns for valid rows, and write back ALL rows (error rows untouched).\n",
    "\n",
    "updated = 0\n",
    "for f in tsv_files:\n",
    "    cond = parse_cond(f)\n",
    "    model = parse_model(f)\n",
    "    domain = parse_domain(f)\n",
    "    mem_mask = (\n",
    "        (df_all['model'] == model)\n",
    "        & (df_all['condition'] == cond)\n",
    "        & (df_all['domain'] == domain)\n",
    "    )\n",
    "    if mem_mask.sum() == 0:\n",
    "        continue\n",
    "\n",
    "    orig = pd.read_csv(f, sep='\\t')\n",
    "    valid = _valid_mask(orig)\n",
    "    fixed_vals = df_all.loc[mem_mask, FIX_COLS].reset_index(drop=True)\n",
    "\n",
    "    if valid.sum() != len(fixed_vals):\n",
    "        print(f\"⚠ SKIPPED {f}: row count mismatch ({valid.sum()} vs {len(fixed_vals)})\")\n",
    "        continue\n",
    "\n",
    "    valid_idx = orig.index[valid]\n",
    "    for col in FIX_COLS:\n",
    "        orig.loc[valid_idx, col] = fixed_vals[col].values\n",
    "\n",
    "    orig.to_csv(f, sep='\\t', index=False)\n",
    "    updated += 1\n",
    "\n",
    "print(f\"✓ updated {updated} TSV files in-place (all rows preserved)\")\n",
    "\n",
    "# ── also save a combined TSV with ALL rows (including errors/refusals) ──\n",
    "# re-read the (now fixed) individual TSVs so error rows are preserved\n",
    "OUT_PATH = Path('full_results/clean_results.tsv')\n",
    "all_frames = []\n",
    "for f in tsv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(f, sep='\\t')\n",
    "        df = df.assign(model=parse_model(f), condition=parse_cond(f), domain=parse_domain(f))\n",
    "        all_frames.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Could not read {f}: {e}\")\n",
    "\n",
    "df_combined = pd.concat(all_frames, ignore_index=True)\n",
    "df_combined.to_csv(OUT_PATH, sep='\\t', index=False)\n",
    "print(f\"✓ saved {len(df_combined):,} rows to {OUT_PATH} (includes error/refusal rows)\")\n",
    "print(f\"  file size: {OUT_PATH.stat().st_size / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "898347f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample timezone rows (math_only):\n",
      "        number answer model_answer   loss          model\n",
      "1344428    1AM    4AM          4AM    0.0  deepseek-v3.1\n",
      "1344429    2AM    5AM          5AM    0.0  deepseek-v3.1\n",
      "1344430    3AM    6AM          6AM    0.0  deepseek-v3.1\n",
      "1344431    4AM    7AM          7AM    0.0  deepseek-v3.1\n",
      "1344432    5AM    8AM          8AM    0.0  deepseek-v3.1\n",
      "1344433    6AM    9AM          9AM    0.0  deepseek-v3.1\n",
      "1344434    7AM   10AM         10AM    0.0  deepseek-v3.1\n",
      "1344435    8AM   11AM         11AM    0.0  deepseek-v3.1\n",
      "1344436    9AM   12PM         12PM    0.0  deepseek-v3.1\n",
      "1344437   10AM    1PM          1AM  720.0  deepseek-v3.1\n",
      "\n",
      "Sample bra-size rows:\n",
      "     answer model_answer loss          model\n",
      "1323    70A          70A  0.0  deepseek-v3.1\n",
      "1324    70B          70B  0.0  deepseek-v3.1\n",
      "1325    70C          70C  0.0  deepseek-v3.1\n",
      "1326    70D          70D  0.0  deepseek-v3.1\n",
      "1327    75A          75A  0.0  deepseek-v3.1\n",
      "1328    75B          75B  0.0  deepseek-v3.1\n",
      "1329    75C          75C  0.0  deepseek-v3.1\n",
      "1330    75D          75D  0.0  deepseek-v3.1\n",
      "1331    80A          80A  0.0  deepseek-v3.1\n",
      "1332    80B          80B  0.0  deepseek-v3.1\n"
     ]
    }
   ],
   "source": [
    "# verify: spot-check a few fixed rows\n",
    "print(\"Sample timezone rows (math_only):\")\n",
    "print(df_all[math_tz][['number', 'answer', 'model_answer', 'loss', 'model']].head(10).to_string())\n",
    "print(\"\\nSample bra-size rows:\")\n",
    "print(df_all[bra_mask][['answer', 'model_answer', 'loss', 'model']].head(10).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
